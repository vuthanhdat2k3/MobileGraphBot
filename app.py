import gradio as gr
from langgraph_rag import chat, chat_neo4j

chat_history_memory = []

with gr.Blocks(title="üì± Phone Specs Chatbot") as demo:
    gr.Markdown("## ü§ñ Tr·ª£ l√Ω AI - H·ªèi g√¨ v·ªÅ ƒëi·ªán tho·∫°i c≈©ng bi·∫øt!")

    chatbot = gr.Chatbot()
    msg = gr.Textbox(placeholder="Nh·∫≠p c√¢u h·ªèi v·ªÅ ƒëi·ªán tho·∫°i...", label="B·∫°n h·ªèi:")
    mode = gr.Radio(["Vector Search (RAG)", "Cypher Query (Graph)"], value="Vector Search (RAG)", label="Ch·∫ø ƒë·ªô tr·∫£ l·ªùi")
    clear = gr.Button("üßπ Xo√° h·ªôi tho·∫°i")

    def respond(user_input, history_ui, selected_mode):
        global chat_history_memory

        if selected_mode == "Vector Search (RAG)":
            result = chat(user_input, chat_history_memory)
            response = result  # S·ª≠a ·ªü ƒë√¢y
            # chat_history_memory = result["chat_history"]  # N·∫øu c·∫ßn l∆∞u history, t·ª± x·ª≠ l√Ω th√™m
        else:  # d√πng Cypher
            results = chat_neo4j(user_input)
            if not results:
                response = "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p."
            else:
                response = "\n".join([str(r) for r in results])

        history_ui.append((user_input, response))
        return "", history_ui

    def clear_all():
        global chat_history_memory
        chat_history_memory = []
        return []

    msg.submit(respond, [msg, chatbot, mode], [msg, chatbot])
    clear.click(clear_all, outputs=chatbot)

demo.launch()
